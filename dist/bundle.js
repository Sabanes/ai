(()=>{"use strict";function t(){return t=Object.assign?Object.assign.bind():function(t){for(var e=1;e<arguments.length;e++){var n=arguments[e];for(var s in n)({}).hasOwnProperty.call(n,s)&&(t[s]=n[s])}return t},t.apply(null,arguments)}function e(t){const e=new Uint8Array(t);return window.btoa(String.fromCharCode(...e))}function n(t){const e=window.atob(t),n=e.length,s=new Uint8Array(n);for(let t=0;t<n;t++)s[t]=e.charCodeAt(t);return s.buffer}const s=new Blob(['\n      const TARGET_SAMPLE_RATE = 16000;\n      class RawAudioProcessor extends AudioWorkletProcessor {\n        constructor() {\n          super();\n          this.buffer = []; // Initialize an empty buffer\n          this.bufferSize = TARGET_SAMPLE_RATE / 4; // Define the threshold for buffer size to be ~0.25s\n\n          if (globalThis.LibSampleRate && sampleRate !== TARGET_SAMPLE_RATE) {\n            globalThis.LibSampleRate.create(1, sampleRate, TARGET_SAMPLE_RATE).then(resampler => {\n              this.resampler = resampler;\n            });\n          }\n        }\n        process(inputs, outputs) {\n          const input = inputs[0]; // Get the first input node\n          if (input.length > 0) {\n            let channelData = input[0]; // Get the first channel\'s data\n\n            // Resample the audio if necessary\n            if (this.resampler) {\n              channelData = this.resampler.full(channelData);\n            }\n\n            // Add channel data to the buffer\n            this.buffer.push(...channelData);\n            // Get max volume \n            let sum = 0.0;\n            for (let i = 0; i < channelData.length; i++) {\n              sum += channelData[i] * channelData[i];\n            }\n            const maxVolume = Math.sqrt(sum / channelData.length);\n            // Check if buffer size has reached or exceeded the threshold\n            if (this.buffer.length >= this.bufferSize) {\n              const float32Array = new Float32Array(this.buffer)\n              let pcm16Array = new Int16Array(float32Array.length);\n\n              // Iterate through the Float32Array and convert each sample to PCM16\n              for (let i = 0; i < float32Array.length; i++) {\n                // Clamp the value to the range [-1, 1]\n                let sample = Math.max(-1, Math.min(1, float32Array[i]));\n            \n                // Scale the sample to the range [-32768, 32767] and store it in the Int16Array\n                pcm16Array[i] = sample < 0 ? sample * 32768 : sample * 32767;\n              }\n            \n              // Send the buffered data to the main script\n              this.port.postMessage([pcm16Array, maxVolume]);\n            \n              // Clear the buffer after sending\n              this.buffer = [];\n            }\n          }\n          return true; // Continue processing\n        }\n      }\n      registerProcessor("raw-audio-processor", RawAudioProcessor);\n  '],{type:"application/javascript"}),o=URL.createObjectURL(s);class a{static async create(t){let e=null,n=null;try{const s=navigator.mediaDevices.getSupportedConstraints().sampleRate;e=new window.AudioContext(s?{sampleRate:t}:{});const i=e.createAnalyser();s||await e.audioWorklet.addModule("https://cdn.jsdelivr.net/npm/@alexanderolsen/libsamplerate-js@2.1.2/dist/libsamplerate.worklet.js"),await e.audioWorklet.addModule(o),n=await navigator.mediaDevices.getUserMedia({audio:{sampleRate:{ideal:t},echoCancellation:{ideal:!0}}});const r=e.createMediaStreamSource(n),c=new AudioWorkletNode(e,"raw-audio-processor");return r.connect(i),i.connect(c),new a(e,i,c,n)}catch(t){var s,i;throw null==(s=n)||s.getTracks().forEach((t=>t.stop())),null==(i=e)||i.close(),t}}constructor(t,e,n,s){this.context=void 0,this.analyser=void 0,this.worklet=void 0,this.inputStream=void 0,this.context=t,this.analyser=e,this.worklet=n,this.inputStream=s}async close(){this.inputStream.getTracks().forEach((t=>t.stop())),await this.context.close()}}const i=new Blob(['\n      class AudioConcatProcessor extends AudioWorkletProcessor {\n        constructor() {\n          super();\n          this.buffers = []; // Initialize an empty buffer\n          this.cursor = 0;\n          this.currentBuffer = null;\n          this.wasInterrupted = false;\n          this.finished = false;\n\n          this.port.onmessage = ({ data }) => {\n            switch (data.type) {\n              case "buffer":\n                this.wasInterrupted = false;\n                this.buffers.push(new Int16Array(data.buffer));\n                break;\n              case "interrupt":\n                this.wasInterrupted = true;\n                break;\n              case "clearInterrupted":\n                if (this.wasInterrupted) {\n                  this.wasInterrupted = false;\n                  this.buffers = [];\n                  this.currentBuffer = null;\n                }\n            }\n          };\n        }\n        process(_, outputs) {\n          let finished = false;\n          const output = outputs[0][0];\n          for (let i = 0; i < output.length; i++) {\n            if (!this.currentBuffer) {\n              if (this.buffers.length === 0) {\n                finished = true;\n                break;\n              }\n              this.currentBuffer = this.buffers.shift();\n              this.cursor = 0;\n            }\n\n            output[i] = this.currentBuffer[this.cursor] / 32768;\n            this.cursor++;\n\n            if (this.cursor >= this.currentBuffer.length) {\n              this.currentBuffer = null;\n            }\n          }\n\n          if (this.finished !== finished) {\n            this.finished = finished;\n            this.port.postMessage({ type: "process", finished });\n          }\n\n          return true; // Continue processing\n        }\n      }\n\n      registerProcessor("audio-concat-processor", AudioConcatProcessor);\n    '],{type:"application/javascript"}),r=URL.createObjectURL(i);class c{static async create(t){let e=null;try{e=new AudioContext({sampleRate:t});const n=e.createAnalyser(),s=e.createGain();s.connect(n),n.connect(e.destination),await e.audioWorklet.addModule(r);const o=new AudioWorkletNode(e,"audio-concat-processor");return o.connect(s),new c(e,n,s,o)}catch(t){var n;throw null==(n=e)||n.close(),t}}constructor(t,e,n,s){this.context=void 0,this.analyser=void 0,this.gain=void 0,this.worklet=void 0,this.context=t,this.analyser=e,this.gain=n,this.worklet=s}async close(){await this.context.close()}}function u(t){return!!t.type}class l{static async create(t){let e=null;try{var n,s;const o=null!=(n="undefined"!=typeof process?process.env.ELEVENLABS_CONVAI_SERVER_ORIGIN:null)?n:"wss://api.elevenlabs.io",a=null!=(s="undefined"!=typeof process?process.env.ELEVENLABS_CONVAI_SERVER_PATHNAME:null)?s:"/v1/convai/conversation?agent_id=";e=new WebSocket(t.signedUrl?t.signedUrl:o+a+t.agentId);const i=await new Promise(((t,n)=>{e.addEventListener("error",n),e.addEventListener("close",n),e.addEventListener("message",(e=>{const n=JSON.parse(e.data);u(n)&&("conversation_initiation_metadata"===n.type?t(n.conversation_initiation_metadata_event):console.warn("First received message is not conversation metadata."))}),{once:!0})})),r=i.conversation_id,c=parseInt(i.agent_output_audio_format.replace("pcm_",""));return new l(e,r,c)}catch(t){var o;throw null==(o=e)||o.close(),t}}constructor(t,e,n){this.socket=void 0,this.conversationId=void 0,this.sampleRate=void 0,this.socket=t,this.conversationId=e,this.sampleRate=n}close(){this.socket.close()}}const d={onConnect:()=>{},onDisconnect:()=>{},onError:()=>{},onDebug:()=>{},onMessage:()=>{},onStatusChange:()=>{},onModeChange:()=>{}};class h{static async startSession(e){const n=t({},d,e);n.onStatusChange({status:"connecting"});let s=null,o=null,i=null;try{return s=await a.create(16e3),o=await l.create(e),i=await c.create(o.sampleRate),new h(n,o,s,i)}catch(t){var r,u,p;throw n.onStatusChange({status:"disconnected"}),null==(r=o)||r.close(),await(null==(u=s)?void 0:u.close()),await(null==(p=i)?void 0:p.close()),t}}constructor(t,s,o,a){var i=this;this.options=void 0,this.connection=void 0,this.input=void 0,this.output=void 0,this.lastInterruptTimestamp=0,this.mode="listening",this.status="connecting",this.inputFrequencyData=void 0,this.outputFrequencyData=void 0,this.volume=1,this.endSession=async function(){"connected"===i.status&&(i.updateStatus("disconnecting"),i.connection.close(),await i.input.close(),await i.output.close(),i.updateStatus("disconnected"))},this.updateMode=t=>{t!==this.mode&&(this.mode=t,this.options.onModeChange({mode:t}))},this.updateStatus=t=>{t!==this.status&&(this.status=t,this.options.onStatusChange({status:t}))},this.onEvent=t=>{try{const e=JSON.parse(t.data);if(!u(e))return;switch(e.type){case"interruption":e.interruption_event&&(this.lastInterruptTimestamp=e.interruption_event.event_id),this.fadeOutAudio();break;case"agent_response":this.options.onMessage({source:"ai",message:e.agent_response_event.agent_response});break;case"user_transcript":this.options.onMessage({source:"user",message:e.user_transcription_event.user_transcript});break;case"internal_tentative_agent_response":this.options.onDebug({type:"tentative_agent_response",response:e.tentative_agent_response_internal_event.tentative_agent_response});break;case"audio":this.lastInterruptTimestamp<=e.audio_event.event_id&&(this.addAudioBase64Chunk(e.audio_event.audio_base_64),this.updateMode("speaking"));break;case"ping":this.connection.socket.send(JSON.stringify({type:"pong",event_id:e.ping_event.event_id}));break;default:this.options.onDebug(e)}}catch(e){return void this.onError("Failed to parse event data",{event:t})}},this.onInputWorkletMessage=t=>{const n=JSON.stringify({user_audio_chunk:e(t.data[0].buffer)});"connected"===this.status&&this.connection.socket.send(n)},this.onOutputWorkletMessage=({data:t})=>{"process"===t.type&&this.updateMode(t.finished?"listening":"speaking")},this.addAudioBase64Chunk=async function(t){i.output.gain.gain.value=i.volume,i.output.worklet.port.postMessage({type:"clearInterrupted"}),i.output.worklet.port.postMessage({type:"buffer",buffer:n(t)})},this.fadeOutAudio=async function(){i.updateMode("listening"),i.output.worklet.port.postMessage({type:"interrupt"}),i.output.gain.gain.exponentialRampToValueAtTime(1e-4,i.output.context.currentTime+2),setTimeout((()=>{i.output.gain.gain.value=i.volume,i.output.worklet.port.postMessage({type:"clearInterrupted"})}),2e3)},this.onError=(t,e)=>{console.error(t,e),this.options.onError(t,e)},this.calculateVolume=t=>{if(0===t.length)return 0;let e=0;for(let n=0;n<t.length;n++)e+=t[n]/255;return e/=t.length,e<0?0:e>1?1:e},this.getId=()=>this.connection.conversationId,this.setVolume=({volume:t})=>{this.volume=t},this.getInputByteFrequencyData=()=>(null!=this.inputFrequencyData||(this.inputFrequencyData=new Uint8Array(this.input.analyser.frequencyBinCount)),this.input.analyser.getByteFrequencyData(this.inputFrequencyData),this.inputFrequencyData),this.getOutputByteFrequencyData=()=>(null!=this.outputFrequencyData||(this.outputFrequencyData=new Uint8Array(this.output.analyser.frequencyBinCount)),this.output.analyser.getByteFrequencyData(this.outputFrequencyData),this.outputFrequencyData),this.getInputVolume=()=>this.calculateVolume(this.getInputByteFrequencyData()),this.getOutputVolume=()=>this.calculateVolume(this.getOutputByteFrequencyData()),this.options=t,this.connection=s,this.input=o,this.output=a,this.options.onConnect({conversationId:s.conversationId}),this.connection.socket.addEventListener("message",(t=>{this.onEvent(t)})),this.connection.socket.addEventListener("error",(t=>{this.updateStatus("disconnected"),this.onError("Socket error",t)})),this.connection.socket.addEventListener("close",(()=>{this.updateStatus("disconnected"),this.options.onDisconnect()})),this.input.worklet.port.onmessage=this.onInputWorkletMessage,this.output.worklet.port.onmessage=this.onOutputWorkletMessage,this.updateStatus("connected")}}let p=null;function f(t){const e=document.getElementById("connectionStatus");e.textContent=t?"Connected":"Disconnected",e.classList.toggle("connected",t)}function g(t){const e=document.getElementById("speakingStatus"),n="speaking"===t.mode;e.textContent=n?"Agent Speaking":"Agent Silent",e.classList.toggle("speaking",n),console.log("Speaking status updated:",{mode:t,isSpeaking:n})}document.getElementById("startButton").addEventListener("click",(async function(){const t=document.getElementById("startButton"),e=document.getElementById("endButton");try{if(!await async function(){try{return await navigator.mediaDevices.getUserMedia({audio:!0}),!0}catch(t){return console.error("Microphone permission denied:",t),!1}}())return void alert("Microphone permission is required for the conversation.");const n=await async function(){try{const t=await fetch("/api/signed-url");if(!t.ok)throw new Error("Failed to get signed URL");return(await t.json()).signedUrl}catch(t){throw console.error("Error getting signed URL:",t),t}}();p=await h.startSession({signedUrl:n,onConnect:()=>{console.log("Connected"),f(!0),t.disabled=!0,e.disabled=!1},onDisconnect:()=>{console.log("Disconnected"),f(!1),t.disabled=!1,e.disabled=!0,g({mode:"listening"})},onError:t=>{console.error("Conversation error:",t),alert("Obrigado por usar o Assistente Dia!")},onModeChange:t=>{console.log("Mode changed:",t),g(t)}})}catch(t){console.error("Error starting conversation:",t),alert("Failed to start conversation. Please try again.")}})),document.getElementById("endButton").addEventListener("click",(async function(){p&&(await p.endSession(),p=null)})),window.addEventListener("error",(function(t){console.error("Global error:",t.error)}))})();